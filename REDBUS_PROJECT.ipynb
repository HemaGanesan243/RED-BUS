{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMcFvhanB32T1i/nu4x6+dl",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/HemaGanesan243/RED-BUS/blob/main/REDBUS_PROJECT.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NzG8m8JpOY3s"
      },
      "outputs": [],
      "source": [
        "!pip install selenium"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "links=[\n",
        "       'https://www.redbus.in/online-booking/ktcl/?utm_source=rtchometile',#KADAMBA\n",
        "       'https://www.redbus.in/online-booking/south-bengal-state-transport-corporation-sbstc/?utm_source=rtchometile',#SOUTHBENGAL\n",
        "       'https://www.redbus.in/online-booking/hrtc/?utm_source=rtchometile',#HRTC\n",
        "       'https://www.redbus.in/online-booking/astc/?utm_source=rtchometile', #ASSAM\n",
        "       'https://www.redbus.in/online-booking/wbtc-ctc/?utm_source=rtchometile',#WBTC\n",
        "       'https://www.redbus.in/online-booking/chandigarh-transport-undertaking-ctu',#CHANDIGARH\n",
        "       'https://www.redbus.in/online-booking/pepsu/?utm_source=rtchometile',#PUNJAB\n",
        "       'https://www.redbus.in/online-booking/north-bengal-state-transport-corporation',#NORTHBENGAL\n",
        "       'https://www.redbus.in/online-booking/bihar-state-road-transport-corporation-bsrtc/?utm_source=rtchometile',#BIHAR\n",
        "       'https://www.redbus.in/online-booking/kaac-transport']#KAAC\n",
        "\n",
        "\n",
        "\n",
        "from selenium import webdriver\n",
        "from selenium.webdriver.common.by import By\n",
        "from selenium.webdriver.common.keys import Keys\n",
        "from selenium.webdriver.support.ui import WebDriverWait\n",
        "from selenium.webdriver.support import expected_conditions as EC\n",
        "import time\n",
        "import pandas as pd\n",
        "\n",
        "######################################################NO.0 KADABA##########################################################################3\n",
        "driver = webdriver.Chrome()\n",
        "driver.get(links[0])\n",
        "time.sleep(5)\n",
        "\n",
        "def get_route_links(driver):\n",
        "    route_links = []\n",
        "    try:\n",
        "        body = driver.find_elements(By.XPATH, \"//a[@class='route']\")\n",
        "        route_links = [link.get_attribute('href') for link in body]\n",
        "    except Exception as e:\n",
        "        print(f\"Error in getting route links: {e}\")\n",
        "    return route_links\n",
        "\n",
        "urls_list = get_route_links(driver)\n",
        "df = pd.DataFrame({'URLs': urls_list})\n",
        "\n",
        "def navigate_and_collect_links(driver):\n",
        "    all_links = []\n",
        "    for page_number in range(1,5):  # Adjust the range based on the number of pages you want to navigate\n",
        "        try:\n",
        "            links_on_page = get_route_links(driver)\n",
        "            all_links.extend(links_on_page)\n",
        "            if page_number < 4:  # Only navigate if there are more pages\n",
        "                next_page_button = WebDriverWait(driver, 10).until(\n",
        "                    EC.element_to_be_clickable((By.XPATH, f\"//div[contains(@class, 'DC_117_pageTabs') and text()='{page_number + 1}']\"))\n",
        "                )\n",
        "                driver.execute_script(\"arguments[0].scrollIntoView();\", next_page_button)\n",
        "                time.sleep(1)\n",
        "                print(f\"Clicking on Page {page_number + 1}\")\n",
        "                next_page_button.click()\n",
        "                WebDriverWait(driver, 10).until(EC.text_to_be_present_in_element(\n",
        "                    (By.XPATH, '//div[contains(@class,\"DC_117_pageTabs DC_117_pageActive\")]'),\n",
        "                    str(page_number + 1)))\n",
        "                print(f\"Successfully navigated to page {page_number + 1}\")\n",
        "                time.sleep(3)\n",
        "        except Exception as e:\n",
        "            print(f\"An error occurred while navigating to page {page_number + 1}: {e}\")\n",
        "            break\n",
        "    return all_links\n",
        "\n",
        "all_links = navigate_and_collect_links(driver)\n",
        "\n",
        "\n",
        "def click_view_buses(driver):\n",
        "    b=driver.find_elements(By.CSS_SELECTOR,\"div[class='button']\")\n",
        "    for i in range(len(b)-1,-1,-1):\n",
        "        try:\n",
        "            b[i].click()\n",
        "        except Exception as e:\n",
        "              print()\n",
        "\n",
        "def scroll_down_page(driver):\n",
        "    try:\n",
        "        body = driver.find_element(By.TAG_NAME, \"body\")\n",
        "        for _ in range(14):\n",
        "            body.send_keys(Keys.PAGE_DOWN)\n",
        "            time.sleep(2)\n",
        "    except Exception as e:\n",
        "        print(f\"Error scrolling down the page: {e}\")\n",
        "\n",
        "\n",
        "def extract_bus_data(driver, urls):\n",
        "    bus_data = []\n",
        "    for url in urls:\n",
        "        try:\n",
        "            driver.get(url)\n",
        "            time.sleep(5)  # Wait for the page to load\n",
        "            click_view_buses(driver)\n",
        "            scroll_down_page(driver)\n",
        "\n",
        "\n",
        "            bus_names = driver.find_elements(By.XPATH, \"//div[@class='travels lh-24 f-bold d-color']\")\n",
        "            bus_types = driver.find_elements(By.XPATH, \"//div[@class='bus-type f-12 m-top-16 l-color evBus']\")\n",
        "            departures_time = driver.find_elements(By.XPATH, \"//div[contains(@class, 'dp-time f-19 d-color f-bold')]\")\n",
        "            reachings_time = driver.find_elements(By.XPATH, \"//div[contains(@class, 'bp-time f-19 d-color disp-Inline')]\")\n",
        "            durations = driver.find_elements(By.XPATH, \"//div[contains(@class, 'dur l-color lh-24')]\")\n",
        "            seats_available = driver.find_elements(By.XPATH, \"//div[contains(@class, 'seat-left')]\")\n",
        "            prices = driver.find_elements(By.XPATH, \"//div[contains(@class, 'fare d-block')]\")\n",
        "            star_ratings = driver.find_elements(By.XPATH, \"//div[contains(@class, 'rating-sec lh-24')]\")\n",
        "\n",
        "            for i in range(len(bus_names)):\n",
        "                bus_data.append({\n",
        "                    \"route_link\": url,\n",
        "                    \"bus_name\": bus_names[i].text if i < len(bus_names) else '',\n",
        "                    \"bus_type\": bus_types[i].text if i < len(bus_types) else '',\n",
        "                    \"departure_time\": departures_time[i].text if i < len(departures_time) else '',\n",
        "                    \"reaching_time\": reachings_time[i].text if i < len(reachings_time) else'',\n",
        "                    \"duration\": durations[i].text if i < len(durations) else '',\n",
        "                    \"seats_available\": seats_available[i].text if i < len(seats_available) else '',\n",
        "                    \"price\": prices[i].text if i < len(prices) else '',\n",
        "                    \"star_rating\" : star_ratings[i].text if i < len(star_ratings) else ''\n",
        "                })\n",
        "\n",
        "        except Exception as e:\n",
        "             print(f\"Error extracting data for URL {url}: {e}\")\n",
        "    return bus_data\n",
        "\n",
        "\n",
        "bus_data = extract_bus_data(driver, all_links)\n",
        "for bus in bus_data:\n",
        "    print(bus)\n",
        "\n",
        "driver.quit()\n",
        "\n",
        "bus_dataframe1 = pd.DataFrame(bus_data)\n",
        "bus_dataframe1.to_csv('bus_dataframe1.csv', index=False)\n",
        "\n",
        "\n",
        "#################################################################NO.1 SOUTHBENGAL#####################################################################TSRTC\n",
        "\n",
        "\n",
        "driver = webdriver.Chrome()\n",
        "driver.get(links[1])\n",
        "time.sleep(5)\n",
        "\n",
        "urls_list = get_route_links(driver)\n",
        "df = pd.DataFrame({'URLs': urls_list})\n",
        "\n",
        "def navigate_and_collect_links(driver):\n",
        "    all_links = []\n",
        "    for page_number in range(1,6):\n",
        "        try:\n",
        "            links_on_page = get_route_links(driver)\n",
        "            all_links.extend(links_on_page)\n",
        "            if page_number < 5:  # Only navigate if there are more pages\n",
        "                next_page_button = WebDriverWait(driver, 10).until(\n",
        "                    EC.element_to_be_clickable((By.XPATH, f\"//div[contains(@class, 'DC_117_pageTabs') and text()='{page_number + 1}']\"))\n",
        "                )\n",
        "                driver.execute_script(\"arguments[0].scrollIntoView();\", next_page_button)\n",
        "                time.sleep(1)\n",
        "                print(f\"Clicking on Page {page_number + 1}\")\n",
        "                next_page_button.click()\n",
        "                WebDriverWait(driver, 10).until(EC.text_to_be_present_in_element(\n",
        "                    (By.XPATH, '//div[contains(@class,\"DC_117_pageTabs DC_117_pageActive\")]'),\n",
        "                    str(page_number + 1)))\n",
        "                print(f\"Successfully navigated to page {page_number + 1}\")\n",
        "                time.sleep(3)\n",
        "        except Exception as e:\n",
        "            print(f\"An error occurred while navigating to page {page_number + 1}: {e}\")\n",
        "            break\n",
        "    return all_links\n",
        "\n",
        "all_links = navigate_and_collect_links(driver)\n",
        "bus_data = extract_bus_data(driver, all_links)\n",
        "\n",
        "for bus in bus_data:\n",
        "    print(bus)\n",
        "\n",
        "driver.quit()\n",
        "\n",
        "bus_dataframe2 = pd.DataFrame(bus_data)\n",
        "bus_dataframe2.to_csv('bus_dataframe2.csv', index=False)\n",
        "\n",
        "\n",
        "#############################################################NO.2 HRTC#################################################################################\n",
        "driver = webdriver.Chrome()\n",
        "driver.get(links[2])\n",
        "time.sleep(5)\n",
        "\n",
        "urls_list = get_route_links(driver)\n",
        "df = pd.DataFrame({'URLs': urls_list})\n",
        "\n",
        "def navigate_and_collect_links(driver):\n",
        "    all_links = []\n",
        "    for page_number in range(1,6):\n",
        "        try:\n",
        "            links_on_page = get_route_links(driver)\n",
        "            all_links.extend(links_on_page)\n",
        "            if page_number < 5:  # Only navigate if there are more pages\n",
        "                next_page_button = WebDriverWait(driver, 10).until(\n",
        "                    EC.element_to_be_clickable((By.XPATH, f\"//div[contains(@class, 'DC_117_pageTabs') and text()='{page_number + 1}']\"))\n",
        "                )\n",
        "                driver.execute_script(\"arguments[0].scrollIntoView();\", next_page_button)\n",
        "                time.sleep(1)\n",
        "                print(f\"Clicking on Page {page_number + 1}\")\n",
        "                next_page_button.click()\n",
        "                WebDriverWait(driver, 10).until(EC.text_to_be_present_in_element(\n",
        "                    (By.XPATH, '//div[contains(@class,\"DC_117_pageTabs DC_117_pageActive\")]'),\n",
        "                    str(page_number + 1)))\n",
        "                print(f\"Successfully navigated to page {page_number + 1}\")\n",
        "                time.sleep(3)\n",
        "        except Exception as e:\n",
        "            print(f\"An error occurred while navigating to page {page_number + 1}: {e}\")\n",
        "            break\n",
        "    return all_links\n",
        "\n",
        "all_links = navigate_and_collect_links(driver)\n",
        "\n",
        "bus_data = extract_bus_data(driver, all_links)\n",
        "\n",
        "for bus in bus_data:\n",
        "    print(bus)\n",
        "\n",
        "bus_dataframe3 = pd.DataFrame(bus_data)\n",
        "bus_dataframe3.to_csv('bus_dataframe3.csv', index=False)\n",
        "\n",
        "#############################################################NO.3 ASSAM##########################################################################\n",
        "\n",
        "driver = webdriver.Chrome()\n",
        "driver.get(links[3])\n",
        "time.sleep(5)\n",
        "\n",
        "urls_list = get_route_links(driver)\n",
        "df = pd.DataFrame({'URLs': urls_list})\n",
        "\n",
        "def navigate_and_collect_links(driver):\n",
        "    all_links = []\n",
        "    for page_number in range(1,6):\n",
        "        try:\n",
        "            links_on_page = get_route_links(driver)\n",
        "            all_links.extend(links_on_page)\n",
        "            if page_number < 5:  # Only navigate if there are more pages\n",
        "                next_page_button = WebDriverWait(driver, 10).until(\n",
        "                    EC.element_to_be_clickable((By.XPATH, f\"//div[contains(@class, 'DC_117_pageTabs') and text()='{page_number + 1}']\"))\n",
        "                )\n",
        "                driver.execute_script(\"arguments[0].scrollIntoView();\", next_page_button)\n",
        "                time.sleep(1)\n",
        "                print(f\"Clicking on Page {page_number + 1}\")\n",
        "                next_page_button.click()\n",
        "                WebDriverWait(driver, 10).until(EC.text_to_be_present_in_element(\n",
        "                    (By.XPATH, '//div[contains(@class,\"DC_117_pageTabs DC_117_pageActive\")]'),\n",
        "                    str(page_number + 1)))\n",
        "                print(f\"Successfully navigated to page {page_number + 1}\")\n",
        "                time.sleep(3)\n",
        "        except Exception as e:\n",
        "            print(f\"An error occurred while navigating to page {page_number + 1}: {e}\")\n",
        "            break\n",
        "    return all_links\n",
        "\n",
        "all_links = navigate_and_collect_links(driver)\n",
        "bus_data = extract_bus_data(driver, all_links)\n",
        "\n",
        "for bus in bus_data:\n",
        "    print(bus)\n",
        "\n",
        "driver.quit()\n",
        "\n",
        "bus_dataframe4 = pd.DataFrame(bus_data)\n",
        "bus_dataframe4.to_csv('bus_dataframe4.csv', index=False)\n",
        "\n",
        "\n",
        "##########################################################NO.4 WBTC############################################################################\n",
        "\n",
        "driver = webdriver.Chrome()\n",
        "driver.get(links[4])\n",
        "time.sleep(5)\n",
        "\n",
        "urls_list = get_route_links(driver)\n",
        "df = pd.DataFrame({'URLs': urls_list})\n",
        "\n",
        "def navigate_and_collect_links(driver):\n",
        "    all_links = []\n",
        "    for page_number in range(1,6):\n",
        "        try:\n",
        "            links_on_page = get_route_links(driver)\n",
        "            all_links.extend(links_on_page)\n",
        "            if page_number < 5:  # Only navigate if there are more pages\n",
        "                next_page_button = WebDriverWait(driver, 10).until(\n",
        "                    EC.element_to_be_clickable((By.XPATH, f\"//div[contains(@class, 'DC_117_pageTabs') and text()='{page_number + 1}']\"))\n",
        "                )\n",
        "                driver.execute_script(\"arguments[0].scrollIntoView();\", next_page_button)\n",
        "                time.sleep(1)\n",
        "                print(f\"Clicking on Page {page_number + 1}\")\n",
        "                next_page_button.click()\n",
        "                WebDriverWait(driver, 10).until(EC.text_to_be_present_in_element(\n",
        "                    (By.XPATH, '//div[contains(@class,\"DC_117_pageTabs DC_117_pageActive\")]'),\n",
        "                    str(page_number + 1)))\n",
        "                print(f\"Successfully navigated to page {page_number + 1}\")\n",
        "                time.sleep(3)\n",
        "        except Exception as e:\n",
        "            print(f\"An error occurred while navigating to page {page_number + 1}: {e}\")\n",
        "            break\n",
        "    return all_links\n",
        "\n",
        "all_links = navigate_and_collect_links(driver)\n",
        "\n",
        "bus_data = extract_bus_data(driver, all_links)\n",
        "\n",
        "for bus in bus_data:\n",
        "    print(bus)\n",
        "\n",
        "driver.quit()\n",
        "\n",
        "bus_dataframe5 = pd.DataFrame(bus_data)\n",
        "bus_dataframe5.to_csv('bus_dataframe5.csv', index=False)\n",
        "\n",
        "#############################################################NO.5  CHANDIGARH#############################################################\n",
        "\n",
        "driver = webdriver.Chrome()\n",
        "driver.get(links[5])\n",
        "time.sleep(5)\n",
        "\n",
        "urls_list = get_route_links(driver)\n",
        "df = pd.DataFrame({'URLs': urls_list})\n",
        "\n",
        "\n",
        "def navigate_and_collect_links(driver):\n",
        "    all_links = []\n",
        "    for page_number in range(1,6):\n",
        "        try:\n",
        "            links_on_page = get_route_links(driver)\n",
        "            all_links.extend(links_on_page)\n",
        "            if page_number < 5:  # Only navigate if there are more pages\n",
        "                next_page_button = WebDriverWait(driver, 10).until(\n",
        "                    EC.element_to_be_clickable((By.XPATH, f\"//div[contains(@class, 'DC_117_pageTabs') and text()='{page_number + 1}']\"))\n",
        "                )\n",
        "                driver.execute_script(\"arguments[0].scrollIntoView();\", next_page_button)\n",
        "                time.sleep(1)\n",
        "                print(f\"Clicking on Page {page_number + 1}\")\n",
        "                next_page_button.click()\n",
        "                WebDriverWait(driver, 10).until(EC.text_to_be_present_in_element(\n",
        "                    (By.XPATH, '//div[contains(@class,\"DC_117_pageTabs DC_117_pageActive\")]'),\n",
        "                    str(page_number + 1)))\n",
        "                print(f\"Successfully navigated to page {page_number + 1}\")\n",
        "                time.sleep(3)\n",
        "        except Exception as e:\n",
        "            print(f\"An error occurred while navigating to page {page_number + 1}: {e}\")\n",
        "            break\n",
        "    return all_links\n",
        "\n",
        "all_links = navigate_and_collect_links(driver)\n",
        "bus_data = extract_bus_data(driver, all_links)\n",
        "\n",
        "for bus in bus_data:\n",
        "    print(bus)\n",
        "\n",
        "driver.quit()\n",
        "bus_dataframe6 = pd.DataFrame(bus_data)\n",
        "bus_dataframe6.to_csv('bus_dataframe6.csv', index=False)\n",
        "\n",
        "#############################################################NO.6 PUNJAB#############################################################################\n",
        "\n",
        "driver = webdriver.Chrome()\n",
        "driver.get(links[6])\n",
        "time.sleep(5)\n",
        "\n",
        "urls_list = get_route_links(driver)\n",
        "df = pd.DataFrame({'URLs': urls_list})\n",
        "\n",
        "\n",
        "def navigate_and_collect_links(driver):\n",
        "    all_links = []\n",
        "    for page_number in range(1,4):\n",
        "        try:\n",
        "            links_on_page = get_route_links(driver)\n",
        "            all_links.extend(links_on_page)\n",
        "            if page_number < 3:  # Only navigate if there are more pages\n",
        "                next_page_button = WebDriverWait(driver, 10).until(\n",
        "                    EC.element_to_be_clickable((By.XPATH, f\"//div[contains(@class, 'DC_117_pageTabs') and text()='{page_number + 1}']\"))\n",
        "                )\n",
        "                driver.execute_script(\"arguments[0].scrollIntoView();\", next_page_button)\n",
        "                time.sleep(1)\n",
        "                print(f\"Clicking on Page {page_number + 1}\")\n",
        "                next_page_button.click()\n",
        "                WebDriverWait(driver, 10).until(EC.text_to_be_present_in_element(\n",
        "                    (By.XPATH, '//div[contains(@class,\"DC_117_pageTabs DC_117_pageActive\")]'),\n",
        "                    str(page_number + 1)))\n",
        "                print(f\"Successfully navigated to page {page_number + 1}\")\n",
        "                time.sleep(3)\n",
        "        except Exception as e:\n",
        "            print(f\"An error occurred while navigating to page {page_number + 1}: {e}\")\n",
        "            break\n",
        "    return all_links\n",
        "\n",
        "all_links = navigate_and_collect_links(driver)\n",
        "bus_data = extract_bus_data(driver, all_links)\n",
        "\n",
        "for bus in bus_data:\n",
        "    print(bus)\n",
        "\n",
        "bus_dataframe7 = pd.DataFrame(bus_data)\n",
        "bus_dataframe7.to_csv('bus_dataframe7.csv', index=False)\n",
        "\n",
        "\n",
        "#######################################################NO.7 NORTHBENGAL  ###########################################################################\n",
        "\n",
        "\n",
        "driver = webdriver.Chrome()\n",
        "driver.get(links[7])\n",
        "time.sleep(5)\n",
        "\n",
        "urls_list = get_route_links(driver)\n",
        "df = pd.DataFrame({'URLs': urls_list})\n",
        "\n",
        "\n",
        "def navigate_and_collect_links(driver):\n",
        "    all_links = []\n",
        "    for page_number in range(1,6):\n",
        "        try:\n",
        "            links_on_page = get_route_links(driver)\n",
        "            all_links.extend(links_on_page)\n",
        "            if page_number < 5:  # Only navigate if there are more pages\n",
        "                next_page_button = WebDriverWait(driver, 10).until(\n",
        "                    EC.element_to_be_clickable((By.XPATH, f\"//div[contains(@class, 'DC_117_pageTabs') and text()='{page_number + 1}']\"))\n",
        "                )\n",
        "                driver.execute_script(\"arguments[0].scrollIntoView();\", next_page_button)\n",
        "                time.sleep(1)\n",
        "                print(f\"Clicking on Page {page_number + 1}\")\n",
        "                next_page_button.click()\n",
        "                WebDriverWait(driver, 10).until(EC.text_to_be_present_in_element(\n",
        "                    (By.XPATH, '//div[contains(@class,\"DC_117_pageTabs DC_117_pageActive\")]'),\n",
        "                    str(page_number + 1)))\n",
        "                print(f\"Successfully navigated to page {page_number + 1}\")\n",
        "                time.sleep(3)\n",
        "        except Exception as e:\n",
        "            print(f\"An error occurred while navigating to page {page_number + 1}: {e}\")\n",
        "            break\n",
        "    return all_links\n",
        "\n",
        "all_links = navigate_and_collect_links(driver)\n",
        "bus_data = extract_bus_data(driver, all_links)\n",
        "\n",
        "for bus in bus_data:\n",
        "    print(bus)\n",
        "\n",
        "driver.quit()\n",
        "bus_dataframe8 = pd.DataFrame(bus_data)\n",
        "bus_dataframe8.to_csv('bus_dataframe8.csv', index=False)\n",
        "\n",
        "\n",
        "#################################################################NO.8 BIHAR##########################################################3\n",
        "\n",
        "driver = webdriver.Chrome()\n",
        "driver.get(links[8])\n",
        "time.sleep(5)\n",
        "\n",
        "urls_list = get_route_links(driver)\n",
        "df = pd.DataFrame({'URLs': urls_list})\n",
        "\n",
        "\n",
        "def navigate_and_collect_links(driver):\n",
        "    all_links = []\n",
        "    for page_number in range(1,5):\n",
        "        try:\n",
        "            links_on_page = get_route_links(driver)\n",
        "            all_links.extend(links_on_page)\n",
        "            if page_number < 4:  # Only navigate if there are more pages\n",
        "                next_page_button = WebDriverWait(driver, 10).until(\n",
        "                    EC.element_to_be_clickable((By.XPATH, f\"//div[contains(@class, 'DC_117_pageTabs') and text()='{page_number + 1}']\"))\n",
        "                )\n",
        "                driver.execute_script(\"arguments[0].scrollIntoView();\", next_page_button)\n",
        "                time.sleep(1)\n",
        "                print(f\"Clicking on Page {page_number + 1}\")\n",
        "                next_page_button.click()\n",
        "                WebDriverWait(driver, 10).until(EC.text_to_be_present_in_element(\n",
        "                    (By.XPATH, '//div[contains(@class,\"DC_117_pageTabs DC_117_pageActive\")]'),\n",
        "                    str(page_number + 1)))\n",
        "                print(f\"Successfully navigated to page {page_number + 1}\")\n",
        "                time.sleep(3)\n",
        "        except Exception as e:\n",
        "            print(f\"An error occurred while navigating to page {page_number + 1}: {e}\")\n",
        "            break\n",
        "    return all_links\n",
        "\n",
        "all_links = navigate_and_collect_links(driver)\n",
        "bus_data = extract_bus_data(driver, all_links)\n",
        "\n",
        "for bus in bus_data:\n",
        "    print(bus)\n",
        "driver.quit()\n",
        "\n",
        "bus_dataframe9 = pd.DataFrame(bus_data)\n",
        "bus_dataframe9.to_csv('bus_dataframe9.csv', index=False)\n",
        "\n",
        "############################################################NO.9 KAAC##################################################\n",
        "\n",
        "driver = webdriver.Chrome()\n",
        "driver.get(links[9])\n",
        "time.sleep(5)\n",
        "\n",
        "urls_list = get_route_links(driver)\n",
        "df = pd.DataFrame({'URLs': urls_list})\n",
        "\n",
        "def navigate_and_collect_links(driver):\n",
        "    all_links = []\n",
        "    for page_number in range(1,3):\n",
        "        try:\n",
        "            links_on_page = get_route_links(driver)\n",
        "            all_links.extend(links_on_page)\n",
        "            if page_number < 2:  # Only navigate if there are more pages\n",
        "                next_page_button = WebDriverWait(driver, 10).until(\n",
        "                    EC.element_to_be_clickable((By.XPATH, f\"//div[contains(@class, 'DC_117_pageTabs') and text()='{page_number + 1}']\"))\n",
        "                )\n",
        "                driver.execute_script(\"arguments[0].scrollIntoView();\", next_page_button)\n",
        "                time.sleep(1)\n",
        "                print(f\"Clicking on Page {page_number + 1}\")\n",
        "                next_page_button.click()\n",
        "                WebDriverWait(driver, 10).until(EC.text_to_be_present_in_element(\n",
        "                    (By.XPATH, '//div[contains(@class,\"DC_117_pageTabs DC_117_pageActive\")]'),\n",
        "                    str(page_number + 1)))\n",
        "                print(f\"Successfully navigated to page {page_number + 1}\")\n",
        "                time.sleep(3)\n",
        "        except Exception as e:\n",
        "            print(f\"An error occurred while navigating to page {page_number + 1}: {e}\")\n",
        "            break\n",
        "    return all_links\n",
        "\n",
        "all_links = navigate_and_collect_links(driver)\n",
        "bus_data = extract_bus_data(driver, all_links)\n",
        "\n",
        "\n",
        "for bus in bus_data:\n",
        "    print(bus)\n",
        "\n",
        "driver.quit()\n",
        "\n",
        "bus_dataframe10 = pd.DataFrame(bus_data)\n",
        "bus_dataframe10.to_csv('bus_dataframe10.csv', index=False)\n",
        "\n",
        "all_data=pd.concat([bus_dataframe1, bus_dataframe2,bus_dataframe3,bus_dataframe4,bus_dataframe5,bus_dataframe6,bus_dataframe7,bus_dataframe8,bus_dataframe9,bus_dataframe10],axis=0)\n",
        "print(all_data)\n",
        "\n",
        "df=pd.DataFrame(all_data)\n",
        "df.to_csv('FINAL.csv', index=False)\n",
        "\n",
        "\n",
        "import pandas as pd\n",
        "bus_data = pd.read_csv('FINAL1.csv')\n",
        "\n",
        "\n",
        "import re\n",
        "\n",
        "def extract_route_name(url):\n",
        "    pattern = r'/bus-tickets/([a-zA-Z-]+)'\n",
        "    match = re.search(pattern, url)\n",
        "    if match:\n",
        "        route_name = match.group(1)\n",
        "        return route_name.title()\n",
        "    return None\n",
        "\n",
        "\n",
        "# Apply the function to the route_link column\n",
        "bus_data['route_name'] = bus_data['route_link'].apply(extract_route_name)\n",
        "\n",
        "# Print the resulting DataFrame\n",
        "print(bus_data)\n",
        "\n",
        "import pandas as pd\n",
        "df=pd.DataFrame(bus_data)\n",
        "\n",
        "df.to_csv('FINALFINAL.csv', index=False)\n",
        "\n",
        "df.isnull().sum()\n",
        "df.fillna(0, inplace=True)\n",
        "\n",
        "#######################SQL#########################\n",
        "import pymysql\n",
        "myconnection = pymysql.connect(host='127.0.0.1',user='root',password='root')\n",
        "myconnection.cursor().execute(\"create database redbus\")\n",
        "\n",
        "a=\",\".join(f\"{i} {j}\"\n",
        "for i,j in zip(df.columns,df.dtypes)).replace(\"float64\",\"float\").replace(\"category\",\"text\").replace(\"int64\",\"int\").replace(\"object\",\"text\")\n",
        "\n",
        "f\"create table bus ({a})\"\n",
        "\n",
        "myconnection.cursor().execute(f\"create table redbus.bus ({a})\")\n",
        "\n",
        "len(df)\n",
        "\n",
        "sql = \"insert into redbus.bus values\"\n",
        "for i in range(len(df)):\n",
        "    myconnection.cursor().execute(f\"{sql} {tuple(df.iloc[i])}\")\n",
        "    myconnection.commit()\n",
        "\n",
        "df\n"
      ],
      "metadata": {
        "id": "fYcbccgoOohe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "################################################STREAMLIT#############################################"
      ],
      "metadata": {
        "id": "SWzFZulhPZM1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import streamlit as st\n",
        "import pandas as pd\n",
        "import pymysql\n",
        "from datetime import time\n",
        "\n",
        "st.image(\"C:/Users/Lenovo/Desktop/redbus2.png\")\n",
        "st.title(\":red[RED BUS]\")\n",
        "\n",
        "mydb = pymysql.connect(\n",
        "    host='127.0.0.1',\n",
        "    user='root',\n",
        "    password='root',\n",
        "    database='redbus'\n",
        ")\n",
        "\n",
        "mycursor = mydb.cursor()\n",
        "\n",
        "\n",
        "mycursor.execute('SELECT DISTINCT route_name FROM bus')\n",
        "route_names = mycursor.fetchall()\n",
        "route_name_options = [route[0] for route in route_names]\n",
        "\n",
        "def filter_route_name(search_term):\n",
        "    if search_term == \"\":\n",
        "        return route_name_options\n",
        "    return [option for option in route_name_options if search_term.lower() in option.lower()]\n",
        "\n",
        "search_term = st.text_input('Search:', '')\n",
        "\n",
        "filtered_route_name = filter_route_name(search_term)\n",
        "\n",
        "\n",
        "if filtered_route_name:\n",
        "    selected_option = st.selectbox('Select an option:', filtered_route_name)\n",
        "else:\n",
        "    st.write('No options found.')\n",
        "\n",
        "################## BUS_TYPE\n",
        "\n",
        "query_2 = '''\n",
        "SELECT DISTINCT\n",
        "    bus_type,\n",
        "    CASE\n",
        "        WHEN bus_type LIKE '%NON AC%'\n",
        "             OR bus_type LIKE '%Non A/C%'\n",
        "             OR bus_type LIKE '%NON A/C%'\n",
        "             OR bus_type LIKE '%Non AC%'\n",
        "             OR LOWER(bus_type) LIKE '%non%'\n",
        "             OR LOWER(bus_type) LIKE '%non a/c%'\n",
        "             OR LOWER(bus_type) LIKE '%non ac%'  THEN 'Non A/C'\n",
        "        WHEN bus_type LIKE '%A/C%'\n",
        "             OR bus_type LIKE '%AC%'\n",
        "             OR bus_type LIKE '%a/c%'\n",
        "             OR bus_type LIKE '%ac%' THEN 'A/C'\n",
        "        ELSE 'None of these'\n",
        "    END AS category\n",
        "FROM bus\n",
        "ORDER BY category\n",
        "'''\n",
        "\n",
        "mycursor.execute(query_2)\n",
        "#fetch2 = select * from bus\n",
        "fetch2 = mycursor.fetchall()\n",
        "df_bus_type = pd.DataFrame(fetch2, columns=['bus_type', 'category'])\n",
        "bus_type_list = df_bus_type['category'].unique().tolist()\n",
        "bus_type_list.insert(0, \"Choose your bus_type\")\n",
        "bus_type = st.selectbox(':red[Select Your Bus Type:]', bus_type_list)\n",
        "\n",
        "####### DEPARTURE TIME ############\n",
        "\n",
        "query_3 = '''SELECT DISTINCT departure_time FROM bus'''\n",
        "mycursor.execute(query_3)\n",
        "fetch3 = mycursor.fetchall()\n",
        "df_departure_time = pd.DataFrame(fetch3, columns=['departure_time'])\n",
        "time_format = '%H:%M'\n",
        "df_departure_time['departure_time'] = pd.to_datetime(df_departure_time['departure_time'], format=time_format, errors='coerce')\n",
        "departure_times = [time_obj.time() for time_obj in df_departure_time['departure_time'].dropna()]\n",
        "default_time = departure_times[0] if departure_times else time(0, 0)\n",
        "departure_time = st.time_input(':red[Select Your Departure Time :]', default_time)\n",
        "\n",
        "###############  ARRIVAL TIME ######################\n",
        "query_4 = '''SELECT DISTINCT reaching_time FROM bus'''\n",
        "mycursor.execute(query_4)\n",
        "fetch4 = mycursor.fetchall()\n",
        "df_reaching_time = pd.DataFrame(fetch4, columns=['reaching_time'])\n",
        "time_format = '%H:%M'\n",
        "df_reaching_time['reaching_time'] = pd.to_datetime(df_reaching_time['reaching_time'], format=time_format, errors='coerce')\n",
        "reaching_times = [time_obj.time() for time_obj in df_reaching_time['reaching_time'].dropna()]\n",
        "reaching_time = st.time_input(':red[Select Your Reaching Time :]', default_time)\n",
        "\n",
        "\n",
        "########## STAR RATING\n",
        "\n",
        "query_5 = '''\n",
        "SELECT DISTINCT star_rating\n",
        "FROM bus\n",
        "ORDER BY star_rating DESC '''\n",
        "mycursor.execute(query_5)\n",
        "fetch5 = mycursor.fetchall()\n",
        "df_star_rating = pd.DataFrame(fetch5, columns=['star_rating'])\n",
        "min_star_rating = int(df_star_rating['star_rating'].min())\n",
        "max_star_rating = int(df_star_rating['star_rating'].max())\n",
        "star_rating_range = st.slider(\n",
        "    ':red[Select Your Star Rating Range:]',\n",
        "    min_value=min_star_rating,\n",
        "    max_value=max_star_rating,\n",
        "    value=(min_star_rating, max_star_rating),\n",
        "    step=1\n",
        ")\n",
        "min_star_rating, max_star_rating = star_rating_range\n",
        "\n",
        "########## PRICE\n",
        "\n",
        "query_6 = '''SELECT MIN(CAST(REPLACE(REPLACE(price, 'INR ', ''), ',', '') AS DECIMAL(10, 2))) AS min_price,\n",
        "MAX(CAST(REPLACE(REPLACE(price, 'INR ', ''), ',', '') AS DECIMAL(10, 2))) AS max_price FROM bus'''\n",
        "mycursor.execute(query_6)\n",
        "fetch6 = mycursor.fetchall()\n",
        "min_price = fetch6[0][0] if fetch6[0][0] is not None else 0\n",
        "max_price = fetch6[0][1] if fetch6[0][1] is not None else 0\n",
        "price_range = st.slider(':red[Select Price Range:]', min_value=float(min_price), max_value=float(max_price), value=(float(min_price), float(max_price)), step=0.1)\n",
        "\n",
        "# Submit button\n",
        "if st.button('Submit'):\n",
        "\n",
        "    st.write(f'You selected Route: {selected_option}')\n",
        "    st.write(f'Bus Type: {bus_type}')\n",
        "    st.write(f'Departure Time: {departure_time.strftime(\"%H:%M\")}')\n",
        "    st.write(f'Reaching Time: {reaching_time.strftime(\"%H:%M\")}')\n",
        "    st.write(f'Star Rating: {star_rating_range}')\n",
        "    st.write(f'Price Range: {price_range}')\n",
        "\n",
        "\n",
        "    # Construct and execute the SQL query\n",
        "    query = f'''\n",
        "    SELECT * FROM bus\n",
        "    WHERE route_name = '{selected_option}'\n",
        "    AND LOWER('{bus_type}') LIKE LOWER(CONCAT('%', '{bus_type}', '%'))\n",
        "    AND star_rating BETWEEN {min_star_rating} AND {max_star_rating}\n",
        "    AND CAST(REPLACE(REPLACE(price, 'INR ', ''), ',', '') AS DECIMAL(10, 2)) BETWEEN {price_range[0]} AND {price_range[1]}\n",
        "    AND departure_time = '{departure_time.strftime(\"%H:%M\")}'\n",
        "    AND reaching_time = '{reaching_time.strftime(\"%H:%M\")}' '''\n",
        "\n",
        "    try:\n",
        "        mycursor.execute(query)\n",
        "        filtered_data = pd.DataFrame(mycursor.fetchall(), columns=[i[0] for i in mycursor.description])\n",
        "        if filtered_data.empty:\n",
        "            st.write('No results found.')\n",
        "        else:\n",
        "            st.write('Filtered Results:')\n",
        "            st.dataframe(filtered_data)\n",
        "    except Exception as e:\n",
        "        st.error(f\"An error occurred: {e}\")\n",
        "\n",
        "\n",
        "mydb.close()\n"
      ],
      "metadata": {
        "id": "keKPs1dwRpHN"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}